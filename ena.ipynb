{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mάριος Νεκτάριος Σταματόπουλος \n",
    "# Α.Μ. : 1059383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1η Άσκηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data\\healthcare-dataset-stroke-data.csv')\n",
    "df.head()\n",
    "df.drop(index=3116, axis=0, inplace=True)#drop row containing \"Other\" gender\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 25/25 [00:13<00:00,  1.90it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:06<00:00,  6.55s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 45.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "profile.to_file(\"your_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H ανάλυση και η απεικόνιση του Dataset βρίσκεται στο τέλος"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)Finding missing values\n",
    "\n",
    "   1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4524: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "#erasing all problematic columns\n",
    "df_1 = df.drop('bmi', 1,inplace=False)\n",
    "df_1 = df_1.drop('smoking_status', 1)\n",
    "df_1.replace('Unknown',np.NaN,inplace=True)\n",
    "#transformation of data to numerical values\n",
    "df_1[ ['hypertension', 'heart_disease', 'stroke','ever_married'] ].replace( [0,1] ,['No','Yes'] ,inplace=True)\n",
    "df_1.Residence_type.replace(['Urban', 'Rural'], [0, 1], inplace=True)\n",
    "df_1.work_type.replace(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], [0, 1,2,3,4], inplace=True)\n",
    "df_1.ever_married.replace(['No','Yes'],[0,1],inplace=True)\n",
    "df_1.gender.replace(['Male','Female'],[0,1],inplace=True)\n",
    "df_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding indices of missing values\n",
    "df_2=df.copy(deep=True)\n",
    "missing_indexes_smoking=[(df[col][df[col].eq(\"Unknown\")].index[i], df.columns.get_loc(col)) for col in df.columns for i in range(len(df[col][df[col].eq(\"Unknown\")].index))]\n",
    "\n",
    "missing_indexes_bmi=df.index[df['bmi'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leksiko: {'formerly smoked': 884, 'never smoked': 1892, 'smokes': 789}\n"
     ]
    }
   ],
   "source": [
    "#smoking column\n",
    "missing_indexes_smoking_r=[]\n",
    "\n",
    "\n",
    "for i in missing_indexes_smoking:\n",
    "    missing_indexes_smoking_r.append(i[0])\n",
    "\n",
    "leksiko={}\n",
    "for i in range(len(df['smoking_status'])):\n",
    "    if i not in missing_indexes_smoking_r:\n",
    "        val=df['smoking_status'][i]\n",
    "        if val not in leksiko:\n",
    "            leksiko[val]=1\n",
    "        else:\n",
    "            leksiko[val]=leksiko[val]+1\n",
    "\n",
    "print(\"leksiko:\",leksiko)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle: 2\n",
      "<ipython-input-9-be24a0625680>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['smoking_status'][i]=val_to_complete\n",
      "C:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "<ipython-input-9-be24a0625680>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['bmi'][i]=average\n",
      "C:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4524: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "#calculating the average of the 3 categories \n",
    "antistoixia={\"never smoked\":1,\"formerly smoked\":2,\"smokes\":3}\n",
    "inv_antistoixia = {v: k for k, v in antistoixia.items()}\n",
    "\n",
    "middle=0\n",
    "sinolo=0\n",
    "for key in leksiko:\n",
    "    middle=middle+antistoixia[key]*leksiko[key]\n",
    "    sinolo=sinolo+leksiko[key]\n",
    "\n",
    "middle=middle/sinolo\n",
    "middle=int(middle+0.5)\n",
    "print(\"middle:\",middle)\n",
    "val_to_complete=inv_antistoixia[middle]\n",
    "\n",
    "for i in missing_indexes_smoking:\n",
    "    df_2['smoking_status'][i]=val_to_complete\n",
    "\n",
    "#bmi column\n",
    "missing_indexes_bmi_r=missing_indexes_bmi\n",
    "#calculating average\n",
    "athr,counter=0,0\n",
    "for i in range(len(df['bmi'])):\n",
    "    if i not in missing_indexes_bmi_r:\n",
    "        athr=athr+df['bmi'][i]\n",
    "        counter=counter+1\n",
    "\n",
    "average=athr/counter\n",
    "\n",
    "#filling missing values with average\n",
    "for i in missing_indexes_bmi_r:\n",
    "    df_2['bmi'][i]=average\n",
    "\n",
    "df_2.replace('Unknown',np.NaN,inplace=True)\n",
    "df_2[ ['hypertension', 'heart_disease', 'stroke','ever_married'] ].replace( [0,1] ,['No','Yes'] ,inplace=True)\n",
    "df_2.smoking_status.replace(['never smoked', 'formerly smoked', 'smokes'], [0, 1, 2], inplace=True)\n",
    "df_2.Residence_type.replace(['Urban', 'Rural'], [0, 1], inplace=True)\n",
    "df_2.work_type.replace(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], [0, 1,2,3,4], inplace=True)\n",
    "df_2.ever_married.replace(['No','Yes'],[0,1],inplace=True)\n",
    "df_2.gender.replace(['Male','Female'],[0,1],inplace=True)\n",
    "df_2.reset_index(drop=True, inplace=True)\n",
    "#df_2[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df.copy(deep=True)\n",
    "#fixing data\n",
    "df_3.replace('Unknown',np.NaN,inplace=True)\n",
    "df_3[ ['hypertension', 'heart_disease', 'stroke','ever_married'] ].replace( [0,1] ,['No','Yes'] ,inplace=True)\n",
    "df_3.smoking_status.replace(['never smoked', 'formerly smoked', 'smokes'], [0, 1, 2], inplace=True)\n",
    "df_3.Residence_type.replace(['Urban', 'Rural'], [0, 1], inplace=True)\n",
    "df_3.work_type.replace(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], [0, 1,2,3,4], inplace=True)\n",
    "df_3.ever_married.replace(['No','Yes'],[0,1],inplace=True)\n",
    "df_3.gender.replace(['Male','Female'],[0,1],inplace=True)\n",
    "df_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_smoking=[i for i in range(len(df_3)) if i not in missing_indexes_smoking_r]\n",
    "train_data_bmi=[i for i in range(len(df_3)) if i not in missing_indexes_bmi_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection (lst1, lst2):\n",
    "    return list(set(lst1).intersection( set(lst2)) )\n",
    "\n",
    "#get intersection in order to rfemove all missing values\n",
    "train_data_indices=intersection(train_data_smoking, train_data_bmi)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-7add478d7937>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3[colName][index]=val\n",
      "<ipython-input-15-7add478d7937>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3[colName][index]=val\n"
     ]
    }
   ],
   "source": [
    "def fillMissing(colName,train_indices,missing_indices):\n",
    "    global df_3\n",
    "    df_train=df_3.iloc[train_data_indices]\n",
    "    Y=df_train[colName]\n",
    "    X=df_train.drop(columns=['smoking_status','bmi','id'])\n",
    "    \n",
    "    X= X.astype(float)\n",
    "    \n",
    "    linear_regressor = LinearRegression()  # create object for the class\n",
    "    linear_regressor.fit(X, Y)  # perform linear regression\n",
    "    \n",
    "    df_predict=df_3.iloc[missing_indices]\n",
    "    X_predict =df_predict.drop(columns=['smoking_status','bmi','id'])\n",
    "    X_predict = X_predict.astype(float)\n",
    "    predictions=linear_regressor.predict(X_predict)\n",
    "    \n",
    "    for i,val in enumerate(predictions):\n",
    "        val=round(val)\n",
    "        index=missing_indices[i] \n",
    "        df_3[colName][index]=val\n",
    "\n",
    "fillMissing('smoking_status',train_data_indices,missing_indexes_smoking_r)\n",
    "fillMissing('bmi',train_data_indices,missing_indexes_bmi_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4524: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df_4=df.copy(deep=True)\n",
    "#fixing data\n",
    "df_4.replace('Unknown',np.NaN,inplace=True)\n",
    "df_4[ ['hypertension', 'heart_disease', 'stroke','ever_married'] ].replace( [0,1] ,['No','Yes'] ,inplace=True)\n",
    "df_4.smoking_status.replace(['never smoked', 'formerly smoked', 'smokes'], [0, 1, 2], inplace=True)\n",
    "df_4.Residence_type.replace(['Urban', 'Rural'], [0, 1], inplace=True)\n",
    "df_4.work_type.replace(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], [0, 1,2,3,4], inplace=True)\n",
    "df_4.ever_married.replace(['No','Yes'],[0,1],inplace=True)\n",
    "df_4.gender.replace(['Male','Female'],[0,1],inplace=True)\n",
    "df_4.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-91291161af0a>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_4['smoking_status'][index]=predictions[index,0]\n",
      "<ipython-input-17-91291161af0a>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_4['bmi'][index]=predictions[index,1]\n"
     ]
    }
   ],
   "source": [
    "train_cols=set(df_4.columns)\n",
    "\n",
    "train_cols=list( train_cols-set([\"smoking_status\",'bmi']) ) \n",
    "train_data = df_4[df_4['smoking_status'].notna() & df_4['bmi'].notna()]\n",
    "X=train_data[train_cols]\n",
    "Y=train_data[[\"smoking_status\",'bmi']]\n",
    "model = KNeighborsRegressor(n_neighbors=25)\n",
    "model.fit(X,Y)\n",
    "predictions=model.predict(df_4[train_cols]) \n",
    "for i,val in enumerate(predictions[:,0]):\n",
    "    predictions[i,0]=round(val)\n",
    "\n",
    "for index in missing_indexes_smoking_r:\n",
    "    df_4['smoking_status'][index]=predictions[index,0]\n",
    "\n",
    "for index in missing_indexes_bmi_r:\n",
    "    df_4['bmi'][index]=predictions[index,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Dataframe with method 0 :\n",
      "F1 48.44695441710367 %\n",
      "Precision 47.4703557312253 %\n",
      "Recall 49.46457990115321 %\n",
      "================================================================\n",
      "Dataframe with method 1 :\n",
      "F1 48.59211584875302 %\n",
      "Precision 47.446975648075416 %\n",
      "Recall 49.793899422918386 %\n",
      "================================================================\n",
      "Dataframe with method 2 :\n",
      "F1 51.591755388891805 %\n",
      "Precision 56.88096433952787 %\n",
      "Recall 51.35528547201809 %\n",
      "================================================================\n",
      "Dataframe with method 3 :\n",
      "F1 51.01771743074258 %\n",
      "Precision 58.43183609141056 %\n",
      "Recall 51.13883632923368 %\n"
     ]
    }
   ],
   "source": [
    "def RandomForest(df):\n",
    "    X_cols=set(df.columns)\n",
    "    X_cols=list( set(train_cols)-set(['stroke']) ) #remove class column from triainig data \n",
    "    X=df[X_cols]\n",
    "    Y=df['stroke']\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X, Y, test_size=0.25)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=250, bootstrap=False, warm_start=True)\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    print('F1',f1_score(Y_test, Y_pred, average='macro')*100,'%')\n",
    "    print('Precision',precision_score(Y_test, Y_pred, average='macro')*100,'%' )\n",
    "    print('Recall',recall_score(Y_test, Y_pred, average='macro')*100,'%')\n",
    "\n",
    "dataframes=[df_1,df_2,df_3,df_4]\n",
    "for i,df in enumerate(dataframes):\n",
    "    print(\"================================================================\")\n",
    "    print(\"Dataframe with method\",i,\":\")\n",
    "    RandomForest(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2η Άσκηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam_or_not_spam\\spam_or_not_spam.csv\")\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of dictionary for words in Glove Model and save it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "leks={}\n",
    "with open(f'glove.6B.100d.txt', 'r', encoding='utf-8') as file:\n",
    "    for l in file.readlines():\n",
    "        data=l.split()\n",
    "        word=data[0]\n",
    "        data=data[1:]\n",
    "        data=[float(i) for i in data]\n",
    "        if word not in leks:\n",
    "            leks[word]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(leks, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('dictionary.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leks=b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-d5e56641d245>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.email[ind]= np.array( email_word_emb )\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gensim \n",
    "from gensim.parsing.preprocessing import remove_stopwords,stem_text\n",
    "\n",
    "WORD_LIMIT=100\n",
    "df_test=df.copy(deep=True)\n",
    "\n",
    "for ind,email in enumerate (df.email):\n",
    "    email=remove_stopwords(email)\n",
    "    email=gensim.utils.simple_preprocess (email)\n",
    "    \n",
    "    email_word_emb=[]\n",
    "    words_added=0\n",
    "    for word in email:\n",
    "        if (words_added>=WORD_LIMIT):\n",
    "            break\n",
    "        \n",
    "        if word in leks:\n",
    "            email_word_emb.append(leks[word])\n",
    "            words_added=words_added+1\n",
    "    #zero padding\n",
    "    dx=WORD_LIMIT-words_added\n",
    "    if (dx>0):\n",
    "        for i in range(dx):\n",
    "            email_word_emb.append( np.zeros(WORD_LIMIT) )\n",
    "    df_test.email[ind]= np.array( email_word_emb )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Net creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"SpamNet\")\n",
    "model.add(LSTM(int(WORD_LIMIT/2), name='LSTM', input_shape=(WORD_LIMIT, WORD_LIMIT)))\n",
    "model.add(Dense(32, name='Dense_1', activation='relu'))\n",
    "model.add(Dropout(0.2, name='Dropout_1'))\n",
    "model.add(Dense(16, name='Dense_2', activation='relu'))\n",
    "model.add(Dropout(0.05, name='Dropout_2'))\n",
    "model.add(Dense(1, name='Output', activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(list(df_test.email)).astype('float32')\n",
    "Y = np.array(df_test.label)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SpamNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM (LSTM)                  (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 32,377\n",
      "Trainable params: 32,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1752a4ab0d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=64, epochs=50,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 94.06%\n",
      "Precision score: 94.85%\n",
      "Recall Score: 93.37%\n"
     ]
    }
   ],
   "source": [
    "Y_pred =[int(i) for i in  model.predict(X_test) + .5]\n",
    "\n",
    "print(f\"F1 score: {f1_score(Y_test, Y_pred, average='macro') *100:.2f}%\")\n",
    "print(f\"Precision score: {precision_score(Y_test, Y_pred, average='macro')*100:.2f}%\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred, average='macro')*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d1961f880fec64e110a2634d97b12f561cf9a002496e791777f3b256c591f90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1d1961f880fec64e110a2634d97b12f561cf9a002496e791777f3b256c591f90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
